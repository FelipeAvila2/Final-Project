{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries for the API connection\n",
    "\n",
    "import tweepy\n",
    "from tweepy.auth import OAuthHandler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating a dict with the keys for the API connection\n",
    "\n",
    "secrets_dict={}\n",
    "secrets_file = open('tweepy-keys.txt')\n",
    "for line in secrets_file:\n",
    "  (key,value) = line.split(':')\n",
    "  secrets_dict[key] = value[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the API cursor\n",
    "\n",
    "auth = tweepy.OAuthHandler(secrets_dict['API Key'], secrets_dict['API secret'])\n",
    "auth.set_access_token(secrets_dict['Access token'], secrets_dict['Access secret'])\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(words, date_since, numtweet):\n",
    "\n",
    "# Creating DataFrame using pandas\n",
    "  db = pd.DataFrame(columns=['username', 'description', 'location', 'following',\n",
    "              'followers', 'totaltweets', 'retweetcount', 'text', 'hashtags'])\n",
    "\n",
    "# We are using .Cursor() to search through twitter for the required tweets.\n",
    "# The number of tweets can be restricted using .items(number of tweets)\n",
    "  tweets = tweepy.Cursor(api.search, q=words, lang=\"en\",\n",
    "            since=date_since, tweet_mode='extended').items(numtweet)\n",
    "\n",
    "# .Cursor() returns an iterable object. Each item in\n",
    "# the iterator has various attributes that you can access to\n",
    "# get information about each tweet\n",
    "  list_tweets = [tweet for tweet in tweets]\n",
    "\n",
    "# Counter to maintain Tweet Count\n",
    "  i = 1\n",
    "\n",
    "# we will iterate over each tweet in the list for extracting information about each tweet\n",
    "  for tweet in list_tweets:\n",
    "    username = tweet.user.screen_name\n",
    "    description = tweet.user.description\n",
    "    location = tweet.user.location\n",
    "    following = tweet.user.friends_count\n",
    "    followers = tweet.user.followers_count\n",
    "    totaltweets = tweet.user.statuses_count\n",
    "    retweetcount = tweet.retweet_count\n",
    "    hashtags = tweet.entities['hashtags']\n",
    "  \n",
    "# Retweets can be distinguished by a retweeted_status attribute,\n",
    "# in case it is an invalid reference, except block will be executed\n",
    "    try:\n",
    "      text = tweet.retweeted_status.full_text\n",
    "    except AttributeError:\n",
    "      text = tweet.full_text\n",
    "    hashtext = list()\n",
    "    for j in range(0, len(hashtags)):\n",
    "      hashtext.append(hashtags[j]['text'])\n",
    "\n",
    "    # Here we are appending all the extracted information in the DataFrame\n",
    "    ith_tweet = [username, description, location, following,\n",
    "          followers, totaltweets, retweetcount, text, hashtext]\n",
    "    db.loc[len(db)] = ith_tweet\n",
    "\n",
    "  \n",
    "\n",
    "# we will save our database as a CSV file.\n",
    "  return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define forloop that scrapes the necessary tweets and concatenates them\n",
    "\n",
    "import time # twitter limitates the amount of scrapping you can do, so we need to do timesleep\n",
    "from datetime import date\n",
    "\n",
    "# politic is the list of politicians to scrape for\n",
    "# Enter Date since The Tweets are required in yyyy-mm-dd\n",
    "# The minutes its the time it will spend between each iteration of the scrape\n",
    "# numtweet is the number of tweets for each hashtag\n",
    "# file is the older file that i might have and i want to concatenate with\n",
    "\n",
    "# WARNING: Remove the default politicians before deploying\n",
    "\n",
    "def scrapping_engine(date_,politic=['#JoeBiden','#BernieSanders','#MikePence','#TedCruz'], minutes=15, numtweet=500, file=0):\n",
    "\n",
    "    # we need to create a dataframe to deposit the tweets that we scrape\n",
    "\n",
    "    columns = ['target','Unnamed: 0', 'username', 'description', 'location', 'following',\n",
    "           'followers', 'totaltweets', 'retweetcount', 'text', 'hashtags'] # this are the columns that for the dataframe\n",
    "\n",
    "    politic_df = pd.DataFrame(dict(), columns=columns) # creation of the dataframe\n",
    "\n",
    "    # this is the loop for the scrapping of every politician\n",
    "\n",
    "    for element in politic:\n",
    "        subdata = scrape(element, date_, numtweet)\n",
    "        subdata['target'] = element\n",
    "        politic_df = politic_df.append(subdata)\n",
    "        time.sleep(60 * minutes) # need to take it easy!\n",
    "        \n",
    "    csv = file\n",
    "    \n",
    "    politic_df = appending(politic_df, csv)\n",
    "    \n",
    "    spams_count = dict(politic_df['text'].value_counts())\n",
    "\n",
    "    spams = []\n",
    "\n",
    "    for x,y in spams_count.items():\n",
    "        if y > 1:\n",
    "            spams.append(x)\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    politic_df = politic_df.reset_index()\n",
    "\n",
    "    for element in politic_df['text']:\n",
    "        if element in spams:\n",
    "            politic_df.drop(index=counter, inplace=True)\n",
    "        counter += 1\n",
    "    \n",
    "    new_date = 'scraped_from_' + date_ + '_to_' + str(date.today())\n",
    "    \n",
    "    if csv != 0:\n",
    "        politic_df.to_csv(new_date + '.csv', index_label=False)\n",
    "        return politic_df\n",
    "    else:\n",
    "        politic_df.to_csv(new_date + '.csv', index_label=False)\n",
    "        return politic_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that adds the newly scraped file to the rest\n",
    "\n",
    "def appending(db, file):\n",
    "    older = pd.read_csv(file)\n",
    "    return db.append(older) # returns the new database appended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def politicians_input():\n",
    "    print('Enter the politicians names (separated by comma, E.g: ´Joe Biden, Bernie Sanders´): ')\n",
    "    string_ = input()\n",
    "    string = string_.replace(' ','')\n",
    "    list_strings = string.split(',')\n",
    "\n",
    "    return [('#' + x) for x in list_strings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_scrape = politicians_input()\n",
    "\n",
    "# do a function for date input\n",
    "\n",
    "politic_df = scrapping_engine('2021-07-22', to_scrape, 0.1, 10, 'data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "politic_df = pd.read_csv('scraped_from_2021-07-22_to_2021-07-23.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1049, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politic_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>target</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>username</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "      <th>totaltweets</th>\n",
       "      <th>retweetcount</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Michell81478626</td>\n",
       "      <td>I live in Minnesota, I love my cat, dog and bi...</td>\n",
       "      <td>Minnesota, USA</td>\n",
       "      <td>69</td>\n",
       "      <td>12</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>#Congress #chuckSchumer #nancyPelosi #democrat...</td>\n",
       "      <td>['Congress', 'chuckSchumer', 'nancyPelosi', 'd...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DerekOsheaShow</td>\n",
       "      <td>Derek O'Shea Show Politically Homeless Daily C...</td>\n",
       "      <td>Everywhere you want to be</td>\n",
       "      <td>3435</td>\n",
       "      <td>781</td>\n",
       "      <td>5095</td>\n",
       "      <td>0</td>\n",
       "      <td>Who is Defunding Police | Conspiracy Theories ...</td>\n",
       "      <td>['Covid19News', 'JoeBiden', 'BreakingNews', 'p...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tim20026046</td>\n",
       "      <td>White-haired, upper fifties, libertarian dad, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>485</td>\n",
       "      <td>17</td>\n",
       "      <td>4239</td>\n",
       "      <td>98</td>\n",
       "      <td>#JoeBiden Tells The World Another Whopper \"You...</td>\n",
       "      <td>['JoeBiden']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lilgoddamn_III</td>\n",
       "      <td>#bitcoin\\n§LilGoddamn</td>\n",
       "      <td>The Moon 🌕</td>\n",
       "      <td>900</td>\n",
       "      <td>297</td>\n",
       "      <td>28972</td>\n",
       "      <td>57</td>\n",
       "      <td>Democrats Future Agenda...\\n\\n#NacyPelosi :\\nL...</td>\n",
       "      <td>['NacyPelosi', 'JoeBiden']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LisaMaret</td>\n",
       "      <td>Founder, Tea Party WDC \"Return 2 commerce, cha...</td>\n",
       "      <td>Alexandria Va</td>\n",
       "      <td>1446</td>\n",
       "      <td>1735</td>\n",
       "      <td>69535</td>\n",
       "      <td>0</td>\n",
       "      <td>@taxreformer Big surprise, the IRS doesn't aud...</td>\n",
       "      <td>['LarcenousClass', 'Democrats', 'JoeBiden', 'P...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     target  Unnamed: 0         username  \\\n",
       "0      0  #JoeBiden         NaN  Michell81478626   \n",
       "2      2  #JoeBiden         NaN   DerekOsheaShow   \n",
       "3      3  #JoeBiden         NaN      Tim20026046   \n",
       "4      4  #JoeBiden         NaN   lilgoddamn_III   \n",
       "5      5  #JoeBiden         NaN        LisaMaret   \n",
       "\n",
       "                                         description  \\\n",
       "0  I live in Minnesota, I love my cat, dog and bi...   \n",
       "2  Derek O'Shea Show Politically Homeless Daily C...   \n",
       "3  White-haired, upper fifties, libertarian dad, ...   \n",
       "4                              #bitcoin\\n§LilGoddamn   \n",
       "5  Founder, Tea Party WDC \"Return 2 commerce, cha...   \n",
       "\n",
       "                    location  following  followers  totaltweets  retweetcount  \\\n",
       "0             Minnesota, USA         69         12           60             2   \n",
       "2  Everywhere you want to be       3435        781         5095             0   \n",
       "3                        NaN        485         17         4239            98   \n",
       "4                 The Moon 🌕        900        297        28972            57   \n",
       "5              Alexandria Va       1446       1735        69535             0   \n",
       "\n",
       "                                                text  \\\n",
       "0  #Congress #chuckSchumer #nancyPelosi #democrat...   \n",
       "2  Who is Defunding Police | Conspiracy Theories ...   \n",
       "3  #JoeBiden Tells The World Another Whopper \"You...   \n",
       "4  Democrats Future Agenda...\\n\\n#NacyPelosi :\\nL...   \n",
       "5  @taxreformer Big surprise, the IRS doesn't aud...   \n",
       "\n",
       "                                            hashtags  Unnamed: 0.1  \n",
       "0  ['Congress', 'chuckSchumer', 'nancyPelosi', 'd...           NaN  \n",
       "2  ['Covid19News', 'JoeBiden', 'BreakingNews', 'p...           NaN  \n",
       "3                                       ['JoeBiden']           NaN  \n",
       "4                         ['NacyPelosi', 'JoeBiden']           NaN  \n",
       "5  ['LarcenousClass', 'Democrats', 'JoeBiden', 'P...           NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we need to clean the tweets\n",
    "# importing the necessaire packages\n",
    "\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main cleaning step\n",
    "\n",
    "def clean_up(s):\n",
    "    element1 = re.sub('(https?:\\/\\/)?([\\da-z\\.-]+)\\.([a-z\\.]{2,6})([\\/\\w \\.-]*)', '', s) # remove links\n",
    "    element2 = re.sub('[^a-zA-Z0-9]', ' ', element1) # remove non character symbols\n",
    "    element3 = re.sub('amp', '', element2) # twitter has &amp as a special character\n",
    "    return (re.sub('\\d+',' ',element3)).lower() # remove any digits and lowercase everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the text\n",
    "\n",
    "def tokenize(s):\n",
    "    return word_tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize function to help the next function that is lemmatize\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper() # gets first letter of POS categorization\n",
    "    tag_dict = {\"J\": wordnet.ADJ, \n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN) # get returns second argument if first key does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize to reduce the word to it most radical form\n",
    "\n",
    "def lemmatize(l):\n",
    "  \n",
    "    lem = WordNetLemmatizer()\n",
    "    lemmatized = [lem.lemmatize(w,get_wordnet_pos(w)) for w in l]\n",
    "    \n",
    "    return lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the stop words\n",
    "\n",
    "def remove_stopwords(l):\n",
    "    \n",
    "    filtered_sentence = []\n",
    "    \n",
    "    for w in l:\n",
    "        if len(w) > 1:\n",
    "            if w not in stopwords.words('english'):\n",
    "                filtered_sentence.append(w)\n",
    "    \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that combines all of the cleaning functions and does everything\n",
    "\n",
    "def cleaning_engine(df,column='text'):\n",
    "    df['text_processed'] = df[column].apply(clean_up)\n",
    "    df['text_processed'] = df['text_processed'].apply(tokenize)\n",
    "    df['text_processed'] = df['text_processed'].apply(lemmatize)\n",
    "    return df['text_processed'].apply(remove_stopwords)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "politic_df['text_processed'] = cleaning_engine(politic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [congress, chuckschumer, nancypelosi, democrat...\n",
       "2    [defunding, police, conspiracy, theory, town, ...\n",
       "3    [joebiden, tell, world, another, whopper, get,...\n",
       "4    [democrat, future, nacypelosi, latin, future, ...\n",
       "5    [taxreformer, big, surprise, irs, audit, larce...\n",
       "Name: text_processed, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politic_df['text_processed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "politic_df['text_preprocessed'] = politic_df['text'].apply(clean_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = politic_df['text_preprocessed'][0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>target</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>text_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>[congress, chuckschumer, nancypelosi, democrat...</td>\n",
       "      <td>congress  chuckschumer  nancypelosi  democrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>[defunding, police, conspiracy, theory, town, ...</td>\n",
       "      <td>who is defunding police   conspiracy theories ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>[joebiden, tell, world, another, whopper, get,...</td>\n",
       "      <td>joebiden tells the world another whopper  you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>[democrat, future, nacypelosi, latin, future, ...</td>\n",
       "      <td>democrats future a   nacypelosi   latin s are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>[taxreformer, big, surprise, irs, audit, larce...</td>\n",
       "      <td>taxreformer big surprise  the irs doesn t aud...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     target                                     text_processed  \\\n",
       "0      0  #JoeBiden  [congress, chuckschumer, nancypelosi, democrat...   \n",
       "1      2  #JoeBiden  [defunding, police, conspiracy, theory, town, ...   \n",
       "2      3  #JoeBiden  [joebiden, tell, world, another, whopper, get,...   \n",
       "3      4  #JoeBiden  [democrat, future, nacypelosi, latin, future, ...   \n",
       "4      5  #JoeBiden  [taxreformer, big, surprise, irs, audit, larce...   \n",
       "\n",
       "                                   text_preprocessed  \n",
       "0   congress  chuckschumer  nancypelosi  democrat...  \n",
       "1  who is defunding police   conspiracy theories ...  \n",
       "2   joebiden tells the world another whopper  you...  \n",
       "3  democrats future a   nacypelosi   latin s are ...  \n",
       "4   taxreformer big surprise  the irs doesn t aud...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = politic_df[['target','text_processed','text_preprocessed']].reset_index()\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' congress  chuckschumer  nancypelosi  democrats  joebiden  kamalaharris  purplepower the time for action in now  no more vacations  no luncheons it s time to fix this country and get them back on their feet  back to work and out of the bread lines multiple stimulus checks now '"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['text_preprocessed'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ORG': 488,\n",
       "         'NORP': 246,\n",
       "         'PERSON': 450,\n",
       "         'GPE': 404,\n",
       "         'LOC': 16,\n",
       "         'DATE': 68,\n",
       "         'PRODUCT': 36,\n",
       "         'CARDINAL': 29,\n",
       "         'ORDINAL': 14,\n",
       "         'TIME': 11,\n",
       "         'WORK_OF_ART': 3,\n",
       "         'MONEY': 3})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "from pprint import pprint\n",
    "\n",
    "blob = politic_df['text_processed'].tolist()\n",
    "\n",
    "whole = []\n",
    "\n",
    "for element in blob:\n",
    "    whole += element\n",
    "\n",
    "text = ' '.join(whole)\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "\n",
    "labels = [x.label_ for x in doc.ents]\n",
    "display(Counter(labels))\n",
    "\n",
    "items = [x.text for x in doc.ents]\n",
    "counter_items = dict(Counter(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['democrat',\n",
       " 'america',\n",
       " 'american',\n",
       " 'cuba',\n",
       " 'nyc',\n",
       " 'texan',\n",
       " 'mike penny',\n",
       " 'joe biden',\n",
       " 'cnn',\n",
       " 'gop',\n",
       " 'florida',\n",
       " 'senate',\n",
       " 'texas',\n",
       " 'republican',\n",
       " 'one',\n",
       " 'china',\n",
       " 'first',\n",
       " 'usa',\n",
       " 'today',\n",
       " 'msnbc',\n",
       " 'cuban',\n",
       " 'ted cruz',\n",
       " 'morningjoe mikeparson',\n",
       " 'dougducey marcorubio delta variant kristinoem',\n",
       " 'cbs',\n",
       " 'republicoftexas',\n",
       " 'mitchmcconnell',\n",
       " 'kristinoem',\n",
       " 'kevinmccarthy majorietaylorgreene mikeparson',\n",
       " 'marcorubio kristinoem',\n",
       " 'dougducey',\n",
       " 'abc cnn',\n",
       " 'msnbc gop']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = []\n",
    "\n",
    "for x,y in counter_items.items():\n",
    "    if y >= 10:\n",
    "        entities.append(x)\n",
    "        \n",
    "entities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['democrat',\n",
       " 'america',\n",
       " 'american',\n",
       " 'cuba',\n",
       " 'nyc',\n",
       " 'texan',\n",
       " 'mike penny',\n",
       " 'joe biden',\n",
       " 'cnn',\n",
       " 'gop',\n",
       " 'florida',\n",
       " 'senate',\n",
       " 'texas',\n",
       " 'republican',\n",
       " 'one',\n",
       " 'china',\n",
       " 'first',\n",
       " 'usa',\n",
       " 'today',\n",
       " 'msnbc',\n",
       " 'cuban',\n",
       " 'ted cruz',\n",
       " 'cbs',\n",
       " 'republicoftexas',\n",
       " 'mitchmcconnell',\n",
       " 'kristinoem',\n",
       " 'dougducey']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow_vect = CountVectorizer(vocabulary=entities)\n",
    "\n",
    "X = bow_vect.fit_transform(features['text_preprocessed']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X, columns=entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>democrat</th>\n",
       "      <th>america</th>\n",
       "      <th>american</th>\n",
       "      <th>cuba</th>\n",
       "      <th>nyc</th>\n",
       "      <th>texan</th>\n",
       "      <th>mike penny</th>\n",
       "      <th>joe biden</th>\n",
       "      <th>cnn</th>\n",
       "      <th>gop</th>\n",
       "      <th>...</th>\n",
       "      <th>usa</th>\n",
       "      <th>today</th>\n",
       "      <th>msnbc</th>\n",
       "      <th>cuban</th>\n",
       "      <th>ted cruz</th>\n",
       "      <th>cbs</th>\n",
       "      <th>republicoftexas</th>\n",
       "      <th>mitchmcconnell</th>\n",
       "      <th>kristinoem</th>\n",
       "      <th>dougducey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   democrat  america  american  cuba  nyc  texan  mike penny  joe biden  cnn  \\\n",
       "0         0        0         0     0    0      0           0          0    0   \n",
       "\n",
       "   gop  ...  usa  today  msnbc  cuban  ted cruz  cbs  republicoftexas  \\\n",
       "0    0  ...    0      0      0      0         0    0                0   \n",
       "\n",
       "   mitchmcconnell  kristinoem  dougducey  \n",
       "0               0           0          0  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def is_positive(tweet):\n",
    "    if sia.polarity_scores(tweet)[\"compound\"] > 0:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "features['sentiment'] = features['text_preprocessed'].apply(is_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>target</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>[congress, chuckschumer, nancypelosi, democrat...</td>\n",
       "      <td>congress  chuckschumer  nancypelosi  democrat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>[defunding, police, conspiracy, theory, town, ...</td>\n",
       "      <td>who is defunding police   conspiracy theories ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>[joebiden, tell, world, another, whopper, get,...</td>\n",
       "      <td>joebiden tells the world another whopper  you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>[democrat, future, nacypelosi, latin, future, ...</td>\n",
       "      <td>democrats future a   nacypelosi   latin s are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>[taxreformer, big, surprise, irs, audit, larce...</td>\n",
       "      <td>taxreformer big surprise  the irs doesn t aud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     target                                     text_processed  \\\n",
       "0      0  #JoeBiden  [congress, chuckschumer, nancypelosi, democrat...   \n",
       "1      2  #JoeBiden  [defunding, police, conspiracy, theory, town, ...   \n",
       "2      3  #JoeBiden  [joebiden, tell, world, another, whopper, get,...   \n",
       "3      4  #JoeBiden  [democrat, future, nacypelosi, latin, future, ...   \n",
       "4      5  #JoeBiden  [taxreformer, big, surprise, irs, audit, larce...   \n",
       "\n",
       "                                   text_preprocessed  sentiment  \n",
       "0   congress  chuckschumer  nancypelosi  democrat...          0  \n",
       "1  who is defunding police   conspiracy theories ...          0  \n",
       "2   joebiden tells the world another whopper  you...          0  \n",
       "3  democrats future a   nacypelosi   latin s are ...          1  \n",
       "4   taxreformer big surprise  the irs doesn t aud...          1  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intensity(tweet):\n",
    "    return (abs(sia.polarity_scores(tweet)[\"compound\"])+1)**2\n",
    "\n",
    "features['intensity'] = features['text_preprocessed'].apply(intensity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>target</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>text_preprocessed</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>[congress, chuckschumer, nancypelosi, democrat...</td>\n",
       "      <td>congress  chuckschumer  nancypelosi  democrat...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.330813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>[defunding, police, conspiracy, theory, town, ...</td>\n",
       "      <td>who is defunding police   conspiracy theories ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>[joebiden, tell, world, another, whopper, get,...</td>\n",
       "      <td>joebiden tells the world another whopper  you...</td>\n",
       "      <td>0</td>\n",
       "      <td>2.378689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>[democrat, future, nacypelosi, latin, future, ...</td>\n",
       "      <td>democrats future a   nacypelosi   latin s are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.503812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>#JoeBiden</td>\n",
       "      <td>[taxreformer, big, surprise, irs, audit, larce...</td>\n",
       "      <td>taxreformer big surprise  the irs doesn t aud...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.621038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     target                                     text_processed  \\\n",
       "0      0  #JoeBiden  [congress, chuckschumer, nancypelosi, democrat...   \n",
       "1      2  #JoeBiden  [defunding, police, conspiracy, theory, town, ...   \n",
       "2      3  #JoeBiden  [joebiden, tell, world, another, whopper, get,...   \n",
       "3      4  #JoeBiden  [democrat, future, nacypelosi, latin, future, ...   \n",
       "4      5  #JoeBiden  [taxreformer, big, surprise, irs, audit, larce...   \n",
       "\n",
       "                                   text_preprocessed  sentiment  intensity  \n",
       "0   congress  chuckschumer  nancypelosi  democrat...          0   2.330813  \n",
       "1  who is defunding police   conspiracy theories ...          0   1.000000  \n",
       "2   joebiden tells the world another whopper  you...          0   2.378689  \n",
       "3  democrats future a   nacypelosi   latin s are ...          1   1.503812  \n",
       "4   taxreformer big surprise  the irs doesn t aud...          1   1.621038  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('joe', 'biden'), 41),\n",
       " (('town', 'hall'), 22),\n",
       " (('president', 'joebiden'), 17),\n",
       " (('joebiden', 'trump'), 15),\n",
       " (('trump', 'presidenttrump'), 14),\n",
       " (('presidenttrump', 'news'), 14),\n",
       " (('news', 'voterfraud'), 14),\n",
       " (('voterfraud', 'chinavirus'), 14),\n",
       " (('chinavirus', 'covid'), 14),\n",
       " (('potus', 'joebiden'), 13)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder = nltk.collocations.BigramCollocationFinder.from_words(tokenize(text))\n",
    "finder.ngram_fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# think about blobbing the results\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "import itertools\n",
    "\n",
    "def get_most_common_words(amount, column=politic_df['text_processed']):\n",
    "\n",
    "    blob = column.tolist()\n",
    "\n",
    "    blob = itertools.chain.from_iterable(blob)\n",
    "\n",
    "    fdist = FreqDist(blob)\n",
    "\n",
    "    common = dict(fdist.most_common(amount)) # review this number\n",
    "\n",
    "    return list(common.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1000 = get_most_common_words(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add anything that was not included in that list\n",
    "\n",
    "#spams.append('good morning happy friday mikepence even trust secret service protect jan th fear coup maga gallows ready still call donald trump personal friend mary trump need write book abt psycho mike penny morningjoe penny co rz sbyy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now can start developing the features for our model\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# first i will vectorize all of the words in each tweet by the most common words\n",
    "\n",
    "bow_vect = CountVectorizer(vocabulary=most_common, max_features=1000)\n",
    "\n",
    "# fit creates one entry for each different word seen\n",
    "\n",
    "X = bow_vect.fit_transform(politic_df['blobbed']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to standardize the features for improving the model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# create object\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# fit\n",
    "\n",
    "scaler.fit(X)\n",
    "\n",
    "# transform \n",
    "\n",
    "X_scaled = scaler.transform(as_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
